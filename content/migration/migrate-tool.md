+++
date = "2017-03-20T22:25:17+11:00"
title = "Migration Tool"
weight = 6
[menu.main]
    parent = "migration"
+++

With the Migration tool you can import SQL data into Dgraph by converting
the SQL tables into a schema and RDF file, and then load the resulting dataset
into Dgraph.

### Command-line options

You can run the Dgraph migrate tool with:

```sh
dgraph migrate [flags]
```

Options:

```txt
Usage:
  dgraph migrate [flags]

Flags:
      --db string              The database to import
  -h, --help                   help for migrate
      --host string            The hostname or IP address of the database server. (default "localhost")
  -o, --output_data string     The data output file (default "sql.rdf")
  -s, --output_schema string   The schema output file (default "schema.txt")
      --password string        The password used for logging in
      --port string            The port of the database server. (default "3306")
  -q, --quiet                  Enable quiet mode to suppress the warning logs
  -p, --separator string       The separator for constructing predicate names (default ".")
      --tables string          The comma separated list of tables to import, an empty string means importing all tables in the database
      --user string            The user for logging in

Global Flags:
      --alsologtostderr                  log to standard error as well as files
      --bindall                          Use 0.0.0.0 instead of localhost to bind to all addresses on local machine. (default true)
      --block_rate int                   Block profiling rate. Must be used along with block profile_mode
      --config string                    Configuration file. Takes precedence over default values, but is overridden to values set with environment variables and flags.
      --cwd string                       Change working directory to the path specified. The parent must exist.
      --expose_trace                     Allow trace endpoint to be accessible from remote
      --log_backtrace_at traceLocation   when logging hits line file:N, emit a stack trace (default :0)
      --log_dir string                   If non-empty, write log files in this directory
      --logtostderr                      log to standard error instead of files
      --profile_mode string              Enable profiling mode, one of [cpu, mem, mutex, block]
  -v, --v Level                          log level for V logs
      --vmodule moduleSpec               comma-separated list of pattern=N settings for file-filtered logging
```

### Deriving a Dgraph schema from SQL

Before converting the data, the migration tool needs to derive the schema of each predicate.
Dgraph follows two simple rules for converting the schema:

1. For plain attributes, there is usually a one-to-one mapping between a SQL data type and the
Dgraph datatype. For instance, a `Body` column in the `Posts` table is of type `text`,
and hence, the predicate `posts.Body` is of type `string`: `posts.Body: string .`
2. The predicates representing inter-object relationships, e.g. `posts.OwnerUserId.`, simply have the type
`[uid]`, meaning following the predicate leads us to a set of other objects.


### Using the Migration tool

Create a `config.properties` file that has the following settings (values should not be in quotes):

```txt
user = <the username for logging in to the SQL database>
password = <the password for logging in to the SQL database>
db = <the SQL database to be migrated>
```

For example:

```txt
user = lucas
password = MySecretPassword123
db = stackoverflow
```

Next, export the SQL database into a schema and RDF file, e.g. the `schema.txt` and `sql.rdf` file below
```sh
dgraph migrate --config config.properties --output_schema schema.txt --output_data sql.rdf
```

{{% notice "note" %}}
If you are connecting to a remote DB (something hosted on AWS, GCP, etc...), you need to pass the following flags
```
-- host <the host of your remote DB>
-- port <if anything other than 3306>
```
{{% /notice %}}

Once the migration tool finishes, two new files will be available:

- an RDF file `sql.rdf` containing all the N-Quad entries,
- and a schema file `schema.txt`.

### Importing the data

The two files can then be imported into Dgraph via the [Dgraph Live Loader]({{< relref "live-loader.md" >}})
or [Bulk Loader]({{< relref "bulk-loader.md" >}}). It's worth pointing out that sometimes you
may want to customize the schema, e.g. adding an index to a predicate, or by
changing an inter-object predicate from unidirectional to bidirectional links by adding the
`@reverse` directive. If you would like such customizations, you should do it by editing
the schema file generated by the migration tool before feeding the files to the Live Loader or Bulk Loader.

{{% notice "tip" %}}
Once you have converted your SQL tables to [RDF N-Quad/Triple](https://www.w3.org/TR/n-quads/), 
you can use [Dgraph Live Loader]({{< relref "/deploy/fast-data-loading/live-loader.md" >}}) or 
[Dgraph Bulk Loader]({{< relref "/deploy/fast-data-loading/bulk-loader.md" >}}) to import your data.
{{% /notice %}}

For example, to import the data into Dgraph using the Live Loader (Dgraph Zero and Alpha servers running on the default ports):

```sh
dgraph live -z localhost:5080 -a localhost:9080 --files sql.rdf --format=rdf --schema schema.txt
```
